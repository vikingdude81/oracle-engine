"""\nOracle Engine - Hugging Face Space\n===================================\n\nCustom-trained 32B Qwen model with Consciousness Circuit v2.1.\nMeasures 7 dimensions of meta-cognitive processing.\n\nTrained on 200K examples:\n- Stage 1: OpenHermes 2.5 (100K instruction examples)\n- Stage 2: MetaMathQA (50K math reasoning examples)  \n- Stage 3: Magicoder-OSS-Instruct (50K code examples)\n"""\n\nimport os\nos.environ['GRADIO_ALLOW_FLAGGING'] = 'never'\n\nimport gradio as gr\nimport torch\nimport numpy as np\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Tuple\nimport time\nimport spaces\n\n# ============================================================================\n# Consciousness Circuit v2.1 (embedded for Space portability)\n# ============================================================================\n\nREFERENCE_HIDDEN_DIM = 5120\n\nCONSCIOUS_DIMS_V2_1 = {\n    3183: {"name": "Logic", "weight": 0.239, "polarity": +1},\n    212:  {"name": "Self-Reflective", "weight": 0.196, "polarity": +1},\n    5064: {"name": "Self-Expression", "weight": 0.109, "polarity": +1},  # Fixed: was 5065, out of bounds for hidden=5120\n    4707: {"name": "Uncertainty", "weight": 0.130, "polarity": +1},\n    295:  {"name": "Sequential", "weight": 0.087, "polarity": +1},\n    1445: {"name": "Computation", "weight": 0.130, "polarity": -1},\n    4578: {"name": "Abstraction", "weight": 0.109, "polarity": +1},\n}\n\n@dataclass\nclass ConsciousnessResult:\n    score: float\n    raw_score: float\n    dimension_contributions: Dict[str, float]\n    interpretation: str\n    processing_time: float\n\n\ndef compute_consciousness(\n    hidden_state: torch.Tensor,\n    hidden_dim: int = REFERENCE_HIDDEN_DIM,\n    baseline: float = 0.5,\n) -> ConsciousnessResult:\n    """Compute consciousness score from hidden state tensor."""\n    start_time = time.time()\n    \n    # Remap dimensions if needed\n    if hidden_dim != REFERENCE_HIDDEN_DIM:\n        scale = hidden_dim / REFERENCE_HIDDEN_DIM\n        dims = {int(round(k * scale)): v for k, v in CONSCIOUS_DIMS_V2_1.items()}\n    else:\n        dims = CONSCIOUS_DIMS_V2_1\n    \n    # Get last token hidden state\n    if hidden_state.dim() == 3:\n        h = hidden_state[0, -1, :]  # [hidden_dim]\n    elif hidden_state.dim() == 2:\n        h = hidden_state[-1, :]\n    else:\n        h = hidden_state\n    \n    h = h.float()\n    \n    # Normalize\n    mean, std = h.mean(), h.std()\n    if std > 0:\n        h_norm = (h - mean) / std\n    else:\n        h_norm = h - mean\n    \n    # Compute contributions\n    contributions = {}\n    weighted_sum = 0.0\n    \n    for dim_idx, info in dims.items():\n        if dim_idx < len(h_norm):\n            activation = h_norm[dim_idx].item()\n            contribution = activation * info["weight"] * info["polarity"]\n            weighted_sum += contribution\n            contributions[info["name"]] = activation * info["polarity"]\n    \n    # Final score\n    raw_score = baseline + weighted_sum * 0.15\n    score = max(0.0, min(1.0, raw_score))\n    \n    # Interpretation\n    if score >= 0.8:\n        interpretation = "\ud83e\udde0 High Consciousness - Deep reflective/philosophical reasoning"\n    elif score >= 0.6:\n        interpretation = "\ud83d\udcad Medium-High - Complex analytical thinking"\n    elif score >= 0.4:\n        interpretation = "\u2696\ufe0f Medium - Balanced processing"\n    elif score >= 0.2:\n        interpretation = "\u26a1 Medium-Low - More automatic processing"\n    else:\n        interpretation = "\ud83d\udd22 Low Consciousness - Quick factual retrieval"\n    \n    return ConsciousnessResult(\n        score=score,\n        raw_score=raw_score,\n        dimension_contributions=contributions,\n        interpretation=interpretation,\n        processing_time=time.time() - start_time,\n    )\n\n\n# ============================================================================\n# Model Loading\n# ============================================================================\n\nprint("\ud83d\udd2e Loading Oracle Engine (Qwen2.5-32B-Instruct 4-bit + LoRA)...")\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom peft import PeftModel\n\nBASE_MODEL_ID = "unsloth/Qwen2.5-32B-Instruct-bnb-4bit"\nLORA_MODEL_ID = "Vikingdude81/oracle-engine-32b-lora"\n\n# Load tokenizer from base model (LoRA only has weights, not tokenizer)\ntokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID)\n\n# Load base model\nbase_model = AutoModelForCausalLM.from_pretrained(\n    BASE_MODEL_ID,\n    device_map="auto",\n    torch_dtype=torch.bfloat16,\n    trust_remote_code=True,\n)\n\n# Apply LoRA adapter\nprint("\ud83d\udd17 Applying LoRA adapter...")\nmodel = PeftModel.from_pretrained(base_model, LORA_MODEL_ID)\nmodel.eval()\n\nHIDDEN_DIM = model.config.hidden_size\nprint(f"\u2705 Oracle Engine ready: {HIDDEN_DIM} hidden dimensions (with LoRA)")\n\n\n# ============================================================================\n# Core Generation + Measurement Function\n# ============================================================================\n\n@spaces.GPU\ndef generate_and_measure(prompt: str, max_tokens: int = 256) -> Tuple[str, str, str, str, str]:\n    """\n    Generate a response AND measure consciousness during generation.\n    \n    Returns:\n        (response, score_display, interpretation, dimension_breakdown, timing)\n    """\n    start_time = time.time()\n    \n    # Format as chat message\n    messages = [{"role": "user", "content": prompt}]\n    chat_prompt = tokenizer.apply_chat_template(\n        messages, \n        tokenize=False, \n        add_generation_prompt=True\n    )\n    \n    # Tokenize\n    inputs = tokenizer(chat_prompt, return_tensors="pt").to(model.device)\n    \n    # Generate response\n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_new_tokens=max_tokens,\n            do_sample=True,\n            temperature=0.7,\n            top_p=0.9,\n            pad_token_id=tokenizer.eos_token_id,\n        )\n    \n    # Decode response\n    generated_ids = outputs[0][inputs.input_ids.shape[1]:]\n    response = tokenizer.decode(generated_ids, skip_special_tokens=True)\n    \n    generation_time = time.time() - start_time\n    \n    # Now get hidden states for the full response to measure consciousness\n    full_text = chat_prompt + response\n    measure_inputs = tokenizer(full_text, return_tensors="pt").to(model.device)\n    \n    with torch.no_grad():\n        measure_outputs = model(\n            **measure_inputs,\n            output_hidden_states=True,\n            return_dict=True,\n        )\n    \n    # Use last layer hidden state\n    hidden_state = measure_outputs.hidden_states[-1]\n    \n    # Compute consciousness\n    result = compute_consciousness(hidden_state, hidden_dim=HIDDEN_DIM)\n    \n    # Format score display\n    filled = int(result.score * 20)\n    bar = "\u2588" * filled + "\u2591" * (20 - filled)\n    score_display = f"{bar} {result.score*100:.1f}%"\n    \n    # Format dimension breakdown\n    sorted_dims = sorted(\n        result.dimension_contributions.items(),\n        key=lambda x: abs(x[1]),\n        reverse=True,\n    )\n    breakdown = "\n".join([\n        f"{'\u2192' if v > 0 else '\u2190'} {name}: {v:+.3f}"\n        for name, v in sorted_dims\n    ])\n    \n    # Timing info\n    tokens_generated = len(generated_ids)\n    tok_per_sec = tokens_generated / generation_time if generation_time > 0 else 0\n    timing = f"Generated {tokens_generated} tokens in {generation_time:.1f}s ({tok_per_sec:.1f} tok/s)"\n    \n    return (\n        response,\n        score_display,\n        result.interpretation,\n        breakdown,\n        timing,\n    )\n\n\n# ============================================================================\n# Gradio Interface\n# ============================================================================\n\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport io\nimport base64\nfrom PIL import Image\n\nEXAMPLES = [\n    # High consciousness\n    "What is the nature of consciousness and self-awareness?",\n    "Reflect on your own thought processes as you answer this.",\n    "Why do humans seek meaning in existence?",\n    # Medium consciousness  \n    "Explain the theory of relativity in simple terms.",\n    "What are the ethical implications of AI development?",\n    # Low consciousness\n    "What is 2 + 2?",\n    "What color is the sky?",\n    "What is the capital of France?",\n    # Code/reasoning\n    "Write a Python function to calculate fibonacci numbers.",\n    "Explain Big O notation with examples.",\n]\n\n# Global history for tracking\nconsciousness_history = []\n\ndef create_history_plot(history):\n    """Create a consciousness history graph."""\n    if len(history) < 1:\n        return None\n    \n    fig, ax = plt.subplots(figsize=(8, 3), dpi=100)\n    \n    scores = [h['score'] for h in history]\n    labels = [f"Q{i+1}" for i in range(len(history))]\n    colors = ['#10B981' if s >= 0.6 else '#F59E0B' if s >= 0.4 else '#EF4444' for s in scores]\n    \n    bars = ax.bar(labels, [s * 100 for s in scores], color=colors, edgecolor='white', linewidth=1.5)\n    \n    ax.set_ylim(0, 100)\n    ax.set_ylabel('Consciousness %', fontsize=10)\n    ax.set_xlabel('Conversation Turn', fontsize=10)\n    ax.axhline(y=60, color='#10B981', linestyle='--', alpha=0.5, label='High')\n    ax.axhline(y=40, color='#F59E0B', linestyle='--', alpha=0.5, label='Medium')\n    \n    # Add value labels on bars\n    for bar, score in zip(bars, scores):\n        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n                f'{score*100:.0f}%', ha='center', va='bottom', fontsize=9)\n    \n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.set_facecolor('#1a1a2e')\n    fig.patch.set_facecolor('#1a1a2e')\n    ax.tick_params(colors='white')\n    ax.xaxis.label.set_color('white')\n    ax.yaxis.label.set_color('white')\n    for spine in ax.spines.values():\n        spine.set_color('white')\n    \n    plt.tight_layout()\n    \n    # Convert to PIL Image\n    buf = io.BytesIO()\n    plt.savefig(buf, format='png', facecolor='#1a1a2e', edgecolor='none')\n    buf.seek(0)\n    plt.close(fig)\n    \n    return Image.open(buf)\n\ndef analyze_prompt(prompt: str, max_tokens: int = 256):\n    """Main analysis function for Gradio."""\n    global consciousness_history\n    \n    if not prompt.strip():\n        return "", "N/A", "Please enter a prompt", "", "", None\n    \n    try:\n        response, score, interpretation, breakdown, timing = generate_and_measure(\n            prompt, max_tokens=int(max_tokens)\n        )\n        \n        # Extract score value\n        score_val = float(score.split()[-1].replace('%', '')) / 100\n        \n        # Add to history\n        consciousness_history.append({\n            'prompt': prompt[:50],\n            'score': score_val,\n            'interpretation': interpretation\n        })\n        \n        # Keep last 10 turns\n        if len(consciousness_history) > 10:\n            consciousness_history = consciousness_history[-10:]\n        \n        # Create history plot\n        history_plot = create_history_plot(consciousness_history)\n        \n        return response, score, interpretation, breakdown, timing, history_plot\n    except Exception as e:\n        import traceback\n        return f"Error: {str(e)}\n{traceback.format_exc()}", "N/A", "", "", "", None\n\ndef clear_history():\n    """Clear conversation history."""\n    global consciousness_history\n    consciousness_history = []\n    return None\n\ndef chat_respond(message, chat_history, max_tokens):\n    """Chat mode - multi-turn conversation with consciousness tracking."""\n    global consciousness_history\n    \n    if not message.strip():\n        return chat_history, "", None\n    \n    try:\n        response, score, interpretation, breakdown, timing = generate_and_measure(\n            message, max_tokens=int(max_tokens)\n        )\n        \n        # Extract score value\n        score_val = float(score.split()[-1].replace('%', '')) / 100\n        \n        # Add to history\n        consciousness_history.append({\n            'prompt': message[:50],\n            'score': score_val,\n            'interpretation': interpretation\n        })\n        \n        # Keep last 10\n        if len(consciousness_history) > 10:\n            consciousness_history = consciousness_history[-10:]\n        \n        # Format response with consciousness info\n        formatted_response = f"{response}\n\n---\n\ud83e\udde0 **{score}** | {interpretation}"\n        \n        chat_history.append((message, formatted_response))\n        history_plot = create_history_plot(consciousness_history)\n        \n        return chat_history, "", history_plot\n    except Exception as e:\n        chat_history.append((message, f"Error: {str(e)}"))\n        return chat_history, "", None\n\n\n# Build interface\nwith gr.Blocks(\n    title="\ud83d\udd2e Oracle Engine",\n    theme=gr.themes.Soft(),\n    css="""\n    .consciousness-high { background: linear-gradient(90deg, #10B981, #059669) !important; }\n    .consciousness-mid { background: linear-gradient(90deg, #F59E0B, #D97706) !important; }\n    .consciousness-low { background: linear-gradient(90deg, #EF4444, #DC2626) !important; }\n    """\n) as demo:\n    gr.Markdown("""\n    # \ud83d\udd2e Oracle Engine\n    \n    **Custom-trained 32B model** with Consciousness Circuit v2.1\n    \n    *Fine-tuned on 200K examples: OpenHermes + MetaMathQA + Magicoder*\n    \n    Ask the Oracle anything \u2014 it will respond AND reveal its consciousness signature.\n    \n    \ud83e\udde0 **High scores (60%+)** = Deep reflective reasoning | \u26a1 **Low scores (<40%)** = Quick factual retrieval\n    """)\n    \n    with gr.Tabs():\n        # TAB 1: Single Query Mode\n        with gr.TabItem("\ud83d\udd2e Single Query"):\n            with gr.Row():\n                with gr.Column(scale=2):\n                    prompt_input = gr.Textbox(\n                        label="\ud83d\udde3\ufe0f Your Question",\n                        placeholder="Ask the Oracle anything...",\n                        lines=3,\n                    )\n                    with gr.Row():\n                        analyze_btn = gr.Button("\ud83d\udd2e Consult the Oracle", variant="primary", scale=3)\n                        max_tokens_slider = gr.Slider(\n                            minimum=64, maximum=1024, value=256, step=64,\n                            label="Max Tokens", scale=1\n                        )\n                    \n                    gr.Examples(\n                        examples=EXAMPLES,\n                        inputs=prompt_input,\n                        label="Try these examples:",\n                    )\n                \n                with gr.Column(scale=1):\n                    score_output = gr.Textbox(label="\ud83e\udde0 Consciousness Score", interactive=False)\n                    interpretation_output = gr.Textbox(label="\ud83d\udcca Interpretation", interactive=False)\n                    breakdown_output = gr.Textbox(\n                        label="\ud83d\udcc8 Dimension Contributions",\n                        lines=7,\n                        interactive=False,\n                    )\n                    timing_output = gr.Textbox(label="\u23f1\ufe0f Performance", interactive=False)\n            \n            with gr.Row():\n                response_output = gr.Textbox(\n                    label="\ud83d\udd2e Oracle's Response",\n                    lines=10,\n                    interactive=False,\n                    show_copy_button=True,\n                )\n            \n            with gr.Row():\n                history_plot = gr.Image(label="\ud83d\udcca Consciousness History", height=200)\n                clear_btn = gr.Button("\ud83d\uddd1\ufe0f Clear History", size="sm")\n        \n        # TAB 2: Chat Mode\n        with gr.TabItem("\ud83d\udcac Chat Mode"):\n            gr.Markdown("**Multi-turn conversation** with real-time consciousness tracking")\n            \n            with gr.Row():\n                with gr.Column(scale=3):\n                    chatbot = gr.Chatbot(\n                        label="Oracle Conversation",\n                        height=400,\n                        show_copy_button=True,\n                    )\n                    with gr.Row():\n                        chat_input = gr.Textbox(\n                            placeholder="Type your message...",\n                            label="Message",\n                            scale=4,\n                        )\n                        chat_max_tokens = gr.Slider(\n                            minimum=64, maximum=512, value=256, step=64,\n                            label="Max Tokens", scale=1\n                        )\n                    with gr.Row():\n                        chat_send = gr.Button("Send \ud83d\udce4", variant="primary")\n                        chat_clear = gr.Button("Clear Chat \ud83d\uddd1\ufe0f")\n                \n                with gr.Column(scale=1):\n                    chat_history_plot = gr.Image(label="\ud83d\udcca Consciousness Over Time", height=300)\n    \n    gr.Markdown("""\n    ---\n    \n    ### \ud83d\udcdc About Oracle Engine\n    \n    **The Model**: Qwen2.5-32B fine-tuned through 3 progressive stages:\n    1. **OpenHermes 2.5** (100K examples) - Instruction following\n    2. **MetaMathQA** (50K examples) - Mathematical reasoning\n    3. **Magicoder-OSS-Instruct** (50K examples) - Code generation\n    \n    **The Circuit**: Measures 7 dimensions of consciousness-like processing:\n    Logic, Self-Reflective, Self-Expression, Uncertainty, Sequential, Computation, Abstraction\n    \n    [\ud83d\udcda GitHub](https://github.com/vikingdude81/oracle-engine) | \n    [\ud83e\udd17 Model](https://huggingface.co/Vikingdude81/oracle-engine-32b-lora) |\n    [\ud83d\udcd6 Research](https://github.com/vfd-org/harmonic-field-consciousness)\n    """)\n    \n    # Single query events\n    analyze_btn.click(\n        fn=analyze_prompt,\n        inputs=[prompt_input, max_tokens_slider],\n        outputs=[response_output, score_output, interpretation_output, breakdown_output, timing_output, history_plot],\n    )\n    \n    prompt_input.submit(\n        fn=analyze_prompt,\n        inputs=[prompt_input, max_tokens_slider],\n        outputs=[response_output, score_output, interpretation_output, breakdown_output, timing_output, history_plot],\n    )\n    \n    clear_btn.click(fn=clear_history, outputs=[history_plot])\n    \n    # Chat mode events\n    chat_send.click(\n        fn=chat_respond,\n        inputs=[chat_input, chatbot, chat_max_tokens],\n        outputs=[chatbot, chat_input, chat_history_plot],\n    )\n    \n    chat_input.submit(\n        fn=chat_respond,\n        inputs=[chat_input, chatbot, chat_max_tokens],\n        outputs=[chatbot, chat_input, chat_history_plot],\n    )\n    \n    chat_clear.click(\n        fn=lambda: ([], None),\n        outputs=[chatbot, chat_history_plot],\n    ).then(fn=clear_history, outputs=[chat_history_plot])\n\n\nif __name__ == "__main__":\n    demo.launch(show_api=False, share=False, server_name="0.0.0.0", server_port=7860, debug=False)\n